{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chahabiscuit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f7dc4bd4cd4a7d9e99da8d74dac785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pox_VLTF3',)]\n",
      "['Pox_VLTF3']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence_info = ''\n",
    "sequence = ''\n",
    "annotation = ''\n",
    "\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "      \n",
    "      \n",
    "    \n",
    "with open('./data/uniprot/frequent_kmers.json', 'r') as fp:\n",
    "    kmers = json.load(fp)\n",
    "\n",
    "dictionary = kmers\n",
    "\n",
    "\n",
    "def word_prob(word): \n",
    "    if word in dictionary:\n",
    "        return dictionary[word] / total\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def words(text): \n",
    "    return re.findall('[A-Z]+', text) \n",
    "\n",
    "# dictionary = Counter(words(open('big.txt').read()))\n",
    "\n",
    "max_word_length = max(map(len, dictionary))\n",
    "total = float(sum(dictionary.values()))\n",
    "print(max_word_length)\n",
    "\n",
    "def viterbi_segment(text):\n",
    "    probs, lasts = [1.0], [0]\n",
    "    for i in range(1, len(text) + 1):\n",
    "        prob_k, k = max((probs[j] * word_prob(text[j:i]), j)\n",
    "        for j in range(max(0, i - max_word_length), i))\n",
    "        probs.append(prob_k)\n",
    "        lasts.append(k)\n",
    "    words = []\n",
    "    i = len(text)\n",
    "    while 0 < i:\n",
    "        words.append(text[lasts[i]:i])\n",
    "        i = lasts[i]\n",
    "    words.reverse()\n",
    "    return words, probs[-1]\n",
    "\n",
    "line_count = 0\n",
    "\n",
    "\n",
    "tagged_annos = []\n",
    "ctr = 0\n",
    "fid = 0\n",
    "tags = []\n",
    "annotations = []\n",
    "sequences = []\n",
    "acc = []\n",
    "for line in tqdm_notebook(open(file_name)):\n",
    "    line_count += 1\n",
    "#     print(line)\n",
    "    if line.startswith('DT') or line.startswith('GN') or line.startswith('RN') or line.startswith('RX') or line.startswith('RA') or line.startswith('DR') or line.startswith('PE'):\n",
    "        continue\n",
    "#     elif line.startswith('RT'):\n",
    "#         tag = line\n",
    "#         print(tag)\n",
    "    elif line.startswith('AC'):\n",
    "        end = line.index(';')\n",
    "        file = line[5:end]\n",
    "        select = \"select pfam from swisspfam where acc_id='\" + file +  \"';\"\n",
    "        mycursor.execute(select)\n",
    "        myresult = mycursor.fetchall()\n",
    "        if len(myresult) != 0:\n",
    "            print(myresult)\n",
    "            for i in range(len(myresult[0])):\n",
    "                tags.append(myresult[0][i])\n",
    "            print(tags)\n",
    "            break\n",
    "        else:\n",
    "            tag = '<UNKNOWN>'\n",
    "            tags.append(tag)\n",
    "#         print(file)\n",
    "#         break\n",
    "    elif line.startswith('SQ'):\n",
    "        sequence_info += line[:-1]\n",
    "        sequence_info.replace('\\n', '')\n",
    "    elif line.startswith(' '):\n",
    "        for c in line:\n",
    "            if c != ' ':\n",
    "                sequence += c\n",
    "    elif line.startswith('/'):\n",
    "        annotation += ' ' + sequence_info\n",
    "        annotation = re.sub(' +', ' ', annotation)\n",
    "        sequence = ''.join(sequence.split('\\n'))\n",
    "        sequence = viterbi_segment(sequence)[0]\n",
    "        seq = ''\n",
    "        for i in sequence:\n",
    "            annotation = annotation + ' ' + i\n",
    "            seq = seq + ' ' + i\n",
    "        annotation = re.sub('\\n', ' ', annotation)\n",
    "        for _ in range(len(myresult[0])):\n",
    "            annotations.append(annotation)\n",
    "            sequences.append(seq)\n",
    "#         print(seq)\n",
    "#         print(annotation)\n",
    "#         print(tags)\n",
    "#         break\n",
    "        ctr += 1\n",
    "        if ctr > 50000:\n",
    "            fid += 1\n",
    "            df1 = pd.DataFrame(list(zip(annotations, tags)), columns=['annotation', 'tag'])\n",
    "            df2 = pd.DataFrame(list(zip(sequences, tags)), columns=['sequence', 'tag'])\n",
    "            df3 = df1[df1['tag'] != '<UNKNOWN>']\n",
    "            df4 = df2[df2['tag'] != '<UNKNOWN>']\n",
    "            df1 = df1[df1['tag'] == '<UNKNOWN>']\n",
    "            df2 = df2[df2['tag'] == '<UNKNOWN>']\n",
    "            df3.to_csv('./data/uniprot/annotations/annotations_'+str(fid)+'.csv')\n",
    "            df4.to_csv('./data/uniprot/sequences/sequences_'+str(fid)+'.csv')\n",
    "            df1.to_csv('./data/uniprot/unknown_annotations/unknown_annotations_'+str(fid)+'.csv')\n",
    "            df2.to_csv('./data/uniprot/unknown_sequences/unknown_sequences_'+str(fid)+'.csv')\n",
    "            print(f'[DUMP] [SESSION-{fid}]')\n",
    "            annotations = []\n",
    "            sequences = []\n",
    "            tags = []\n",
    "            del df1\n",
    "            del df2\n",
    "            del df3\n",
    "            del df4\n",
    "            ctr = 0\n",
    "        annotation = '' \n",
    "        sequence = ''\n",
    "        sequence_info = ''\n",
    "    else:\n",
    "        annotation += ' ' + line\n",
    "\n",
    "fid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(list(zip(annotations, tags)), columns=['annotation', 'tag'])\n",
    "df2 = pd.DataFrame(list(zip(sequences, tags)), columns=['sequence', 'tag'])\n",
    "df3 = df1[df1['tag'] != '<UNKNOWN>']\n",
    "df4 = df2[df2['tag'] != '<UNKNOWN>']\n",
    "df1 = df1[df1['tag'] == '<UNKNOWN>']\n",
    "df2 = df2[df2['tag'] == '<UNKNOWN>']\n",
    "df3.to_csv('./data/uniprot/annotations/annotations_'+str(fid)+'.csv')\n",
    "df4.to_csv('./data/uniprot/sequences/sequences_'+str(fid)+'.csv')\n",
    "df1.to_csv('./data/uniprot/unknown_annotations/unknown_annotations_'+str(fid)+'.csv')\n",
    "df2.to_csv('./data/uniprot/unknown_sequences/unknown_sequences_'+str(fid)+'.csv')\n",
    "print(f'[DUMP] [SESSION-{fid}]')\n",
    "annotations = []\n",
    "sequences = []\n",
    "tags = []\n",
    "ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sent_tokenize(tag):\n",
    "    print(word_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'hola        ax ascs'\n",
    "print(x)\n",
    "x = re.sub(' +', ' ', x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "f = 'C:\\\\Users\\\\chahabiscuit\\\\Desktop\\\\polarity.csv'\n",
    "polarity = pd.read_csv(f)\n",
    "polarity = polarity.values\n",
    "print(len(polarity))\n",
    "print(len(polarity[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "polarity_probs = {}\n",
    "tags = [i[0] for i in polarity]\n",
    "aa = {\n",
    "    'Ala':'A',\n",
    "    'Cys':'C',\n",
    "    'Asp':'D',\n",
    "    'Glu':'E',\n",
    "    'Phe':'F',\n",
    "    'Gly':'G',\n",
    "    'His':'H',\n",
    "    'Ile':'I',\n",
    "    'Lys':'K',\n",
    "    'Leu':'L',\n",
    "    'Met':'M',\n",
    "    'Asn':'N',\n",
    "    'Pro':'P',\n",
    "    'Gln':'Q',\n",
    "    'Arg':'R',\n",
    "    'Ser':'S',\n",
    "    'Thr':'T',\n",
    "    'Val':'V',\n",
    "    'Trp':'W',\n",
    "    'Tyr':'Y',\n",
    "}\n",
    "for i in polarity:\n",
    "    for j in range(1, 21):\n",
    "        if math.isnan(i[j]):\n",
    "            polarity_probs[aa[i[0]] + aa[polarity[j-1][0]]] = 1\n",
    "        else:\n",
    "            polarity_probs[aa[i[0]] + aa[polarity[j-1][0]]] = round(1-i[j], 2)\n",
    "polarity_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = {}\n",
    "for file in tqdm_notebook(os.listdir(datadir)):\n",
    "    with open(datadir + '/' + file, 'r') as fp:\n",
    "        seqs[file[:-5]] = str(json.load(fp))\n",
    "print(len(list(seqs.keys())))\n",
    "with open(datadir + '/FASTA.json', 'w') as fp:\n",
    "    json.dump(seqs, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all sequences to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"chahabiscuit\",\n",
    "  password=\"1234\",\n",
    "  database=\"uniprot\",\n",
    ")\n",
    "\n",
    "print(\"Connection to DB established ....\")\n",
    "\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert = \"INSERT INTO kmers (kmer, frequency) VALUES (%s, %s)\"\n",
    "print(\"SQL standard query initialized...\")\n",
    "\n",
    "seq = 'ZZZ'\n",
    "select = \"SELECT frequency FROM kmers WHERE kmer ='\" + seq + \"'\"\n",
    "mycursor.execute(select)\n",
    "myresult = mycursor.fetchall()\n",
    "print(myresult[0][0])\n",
    "if len(myresult) == 0:\n",
    "    val = (seq, 1)\n",
    "    mycursor.execute(insert, val)\n",
    "    print(val)\n",
    "    print('[INSERTION]')\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-mer finding\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "datadir = './data/uniprot/Sequences/FASTA.json'\n",
    "minl = 0\n",
    "kmers = []\n",
    "with open(datadir, 'r') as fp:\n",
    "    fasta = json.load(fp)\n",
    "\n",
    "kmers = {}\n",
    "ctr = 0\n",
    "fid = 0\n",
    "for acc_id, sequence in tqdm_notebook(fasta.items()):\n",
    "    for length in range(2, len(sequence)):\n",
    "        for i in range(0, len(sequence)-length+1, length):\n",
    "#             seq = sequence[i:i+length]\n",
    "#             select = \"SELECT frequency FROM kmers WHERE kmer ='\" + seq + \"'\"\n",
    "#             mycursor.execute(select)\n",
    "#             myresult = mycursor.fetchall()\n",
    "#             if len(myresult) == 0:\n",
    "#                 val = (seq, 1)\n",
    "#                 mycursor.execute(insert, val)\n",
    "#                 mydb.commit()\n",
    "#             else:\n",
    "#                 freq = myresult[0][0] + 1\n",
    "#                 update = \"UPDATE kmers SET frequency = '\" + str(freq) + \"' WHERE kmer = '\" + seq + \"'\"\n",
    "#                 mycursor.execute(update)\n",
    "#                 mydb.commit()\n",
    "\n",
    "            if sequence[i:i+length] in kmers:\n",
    "                kmers[sequence[i:i+length]] += 1\n",
    "            else:\n",
    "                kmers[sequence[i:i+length]] = 1\n",
    "\n",
    "\n",
    "    ctr += 1\n",
    "    if ctr >= 5000:\n",
    "        fid += 1\n",
    "        ctr = 0\n",
    "        with open('./data/uniprot/KMERS/KMERS' + str(fid) + '.json', 'w') as fp:\n",
    "            json.dump(kmers, fp)\n",
    "        kmers = {}\n",
    "        print(f'{fid}th file dumped')\n",
    "fid += 1\n",
    "with open('./data/uniprot/KMERS/KMERS' + str(fid) + '.json', 'w') as fp:\n",
    "    json.dump(kmers, fp)\n",
    "# with open('./data/uniprot/Sequences/KMERS.json', 'w') as fp:\n",
    "#     json.dump(kmers, fp)\n",
    "# for file in tqdm_notebook(os.listdir(datadir)):\n",
    "#     with open(datadir + '/' + file, 'r') as fp:\n",
    "#         seq = json.load(fp)\n",
    "#     length = 2\n",
    "#     for i in range(0, len(seq)-length+1, length):\n",
    "#         kmer = seq[i:i+length]\n",
    "#         flag = False\n",
    "#         for file in os.listdir(datadir):\n",
    "#             for j in range(0, len(seq1)-length+1, length):\n",
    "#                 kmer1 = seq1[j:j+length]\n",
    "#                 if kmer == kmer1:\n",
    "#                     count += 1\n",
    "#                 if count >= 10000/length:\n",
    "#                     kmers.append(kmer)\n",
    "#                     count = 0\n",
    "#                     flag = True\n",
    "#                     break\n",
    "#             if flag:\n",
    "#                 break\n",
    "#     print(len(kmers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"chahabiscuit\",\n",
    "  password=\"1234\",\n",
    "  database=\"uniprot\",\n",
    ")\n",
    "\n",
    "print(\"Connection to DB established ....\")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "# insert = \"INSERT INTO kmers (kmer, frequency) VALUES (%s, %s)\"\n",
    "# print(\"SQL standard query initialized...\")\n",
    "\n",
    "# seq = 'ZZZ'\n",
    "# select = \"SELECT frequency FROM kmers WHERE kmer ='\" + seq + \"'\"\n",
    "# mycursor.execute(select)\n",
    "# myresult = mycursor.fetchall()\n",
    "# print(myresult)\n",
    "# if len(myresult) == 0:\n",
    "#     val = (seq, 1)\n",
    "#     mycursor.execute(insert, val)\n",
    "#     print(val)\n",
    "#     print('[INSERTION]')\n",
    "#     mydb.commit()\n",
    "\n",
    "import os \n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "root = './data/uniprot/KMERS/'\n",
    "\n",
    "file_names = [i for i in os.listdir(root)]\n",
    "table_name = 'kmers'\n",
    "try:\n",
    "    create_table = \"CREATE TABLE \" + table_name + \" (kmer VARCHAR(100), frequency INT(30))\"\n",
    "    mycursor.execute(create_table)\n",
    "    mydb.commit()\n",
    "    \n",
    "except:\n",
    "    password\n",
    "\n",
    "for i in tqdm_notebook((range(len(file_names)-1))):\n",
    "    with open(root+file_names[i], 'r') as fp:\n",
    "        f1 = json.load(fp)\n",
    "    print(f'{file_names[i]} [LOADED]')\n",
    "    insert = \"INSERT INTO kmers (kmer, frequency) VALUES (%s, %s)\"\n",
    "    for seq, freq in f1.items():\n",
    "        if len(seq) <= 40:\n",
    "            val = (seq, freq)\n",
    "            mycursor.execute(insert, val)\n",
    "    mydb.commit()\n",
    "    print(f'{file_names[i]} [COMMIT]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from tqdm import tqdm_notebook\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"chahabiscuit\",\n",
    "  password=\"1234\",\n",
    "  database=\"uniprot\",\n",
    ")\n",
    "\n",
    "print(\"Connection to DB established ....\")\n",
    "\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for length in tqdm_notebook(range(2, 41)):\n",
    "    query1 = \"create table kmers_len_\" + str(length) + \" as select * from kmers where length(kmer)=\" + str(length) + \";\"\n",
    "    query2 = \"create table kmers_len_\" + str(length) + \"x as select kmer, sum(frequency) from kmers_len_\" + str(length) + \" group by kmer;\"\n",
    "    query3 = \"delete from kmers_len_\" + str(length) + \" where 1;\"\n",
    "    query4 = \"drop table kmers_len_\" + str(length) + \";\"\n",
    "    mycursor.execute(query1)\n",
    "    mydb.commit()\n",
    "    mycursor.execute(query2)\n",
    "    mydb.commit()\n",
    "    mycursor.execute(query3)\n",
    "    mydb.commit()\n",
    "    mycursor.execute(query4)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move all annotations to one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('C:/Users/chahabiscuit/Desktop/annotations.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   zipObj.extractall('C:/Users/chahabiscuit/Desktop/annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H', 'e', ' ', 'i', 's', ' ', 'a', ' ', 'b', 'o', 'y']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "list('He is a boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
